---
layout:     post
title:      "Solr使用中文分词"
date:       2016-09-14
author:     "Ryan"
header-img: "img/post-bg-2015.jpg"
tags:
    - solr
---

## 1. Search Engine: solr

Language:
* Java

Latest version:
* 6.1.0
* 5.5.2

### 1.1 Solr Features

Solr is a standalone enterprise search server with a `REST-like API`. You query it via `HTTP GET` and receive `JOSN`, `XML`, `CSV` or `Binary` results.

Solr uses the Lucene search library and extends it.

License: Apache 2.0

### 1.2 Solr的API使用方法

我在这里就不浪费笔墨了,官方文档写了足足700页,非常全.如果想快速入门还有`Quick Start`.

## 2. Chinese Word Segmentation

### 2.1 IK-Analyzer

最新版本发布于2012年,后不再更新.并且其与`solr5`之后有版本兼容问题. 因此该分词组件不予考虑.

### 2.2 mmseg4j-solr

* https://github.com/chenlb/mmseg4j-solr
* `Mar 11, 2015`->`2.3.0`
* `mmseg4j-solr-2.3.0.jar 要求 lucene/solr [5.0, ]`

#### Use mmseg4j-solr

1. put the `.jar` into folder `server/solr-webapp/webapp/WEB-INF/lib/`
2. change `managed-schema` or `schema.xml` add some content.
```xml
   </fieldType>
     <fieldType name="text_zh" class="solr.TextField" positionIncrementGap="100">
     <analyzer>
       <tokenizer class="com.chenlb.mmseg4j.solr.MMSegTokenizerFactory" mode="complex"/>
       <filter class="solr.StopFilterFactory" ignoreCase="true" words="lang/stopwords_zh.txt" />
     </analyzer>
   </fieldType>
```
3. config field using the new `text_zh` type.

经过实际测试,该分词在solr-6.1.0下可以使用,以下两个分词还没有尝试.

### 2.3 ansj_seg

* https://github.com/NLPchina/ansj_seg
* `Jul 30, 2016`->`5.0.1`
* Latest Download: http://maven.nlpcn.org/org/ansj/ansj_seg/
* 2014年6月后原作者没有精力维护,之后交由NLPChina维护,而从2016年1月份开始开发者变得很活跃

### 2.4 Jcseg

* http://git.oschina.net/lionsoul/jcseg
* https://github.com/lionsoul2014/jcseg
* `Jun 11, 2016`->`1.9.7`
* 开发者很活跃
* 默认支持`lucene 6.0`
